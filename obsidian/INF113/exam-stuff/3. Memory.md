# Virtual Memory
*Program code
Global Variables
heap
...
Stack - local variables*

*In an 64 bit computer, you will use 48 bit for virtual user space, *


**Base Pointer** (%rbp)
- Points to a fixed bottom location in the current **stack frame**.
	- A stack frame is a frame of data that gets pushed onto the stack. In the case of a call stack, a stack frame would represent a function call and its argument data
- Used to reference function parameters and local variables with stable offsets within a function's execution.
+ when building uppon the stack, this pointer will swap to the stack pointer
	+ the old basepointer will be saved, and the stack pointer will still point on the top
	+ then new stuff can be saved

**Stack Pointer** (%rsp)
- Points to the **top of the stack**, where the most recent data has been pushed.
- Changes dynamically as values are pushed or popped from the stack.

**Stack and Heap Growth**:
- The stack grows **downward** in memory as data is added (push operations).
- The heap grows **upward** in memory as more dynamic memory is allocated (e.g., with `malloc`).

#### Random but nice to know

| **Value** | **Decimal** | **Hex**    | **Little Endian** | **Big Endian** |
| --------- | ----------- | ---------- | ----------------- | -------------- |
| 1 byte    | 17          | 0x11       | 11                | 11             |
| 2 bytes   | 300         | 0x012c     | 2c 01             | 01 2c          |
| 4 bytes   | 4045364d    | 0x4045364d | 4d 36 45 40       | 40 45 36 4d    |

# Address translation 
*each process got its own visualized memory*
Program code
- The code segment where the instructions live
Heap
- The heap segment contains malloc'd data dynamic data structures (it can grow positively)
stack 
- (it grows negatively) the stack segment: contains local variables arguments to routines. return values. etc.

When multiple processes use the memory
- memory privacy
- needs to be easy to use regardless of process placement
- needs consistent placement of code, stack and heap

**32 bit systems:**
- address space is $2^{32} = 4 GB$
- A 32-bit system can address 4,294,967,296 unique memory locations (or addresses). Since each location corresponds to a single byte, this translates to a maximum of 4 GB of addressable memory.

**64 bit systems:**
- address space is $2^{64} = 16$ exabytes
- A 64-bit system can address an astronomically larger number of unique memory locations—18,446,744,073,709,551,616. This translates to a maximum of 16 exabytes of addressable memory.


# Base & Bounds
- Two more registers in the CPU hardware: base-register  & bound-register
- each process get a value of base and bound, which is moved on context-switch
- base: where memory start
- bound: where memory ends
	- can be absolute or relative 

**How it works**
- OS will find empty physical memory
- Sets base and bound for the new process
- loads code-segment from the disk

**Securing**:
- checking if address is $0<address<bound$
- out of bounds exceptions

**Calculation**
- OS calculates the physical address from virtual space address + base
- it checks if virtual address is within bounds
	- which means the virtual space is restricted
	- 
	
**Dynamic relocation**
- the ability to calculate the physical address translation while running
- the process can be moved after running if that is needed
	- OS copy address space to somewhere else


**Memory Management Unit - MMU**
- base + bound 
- each memory access needs an address translation
-  simple MMU

**Hardware needed**:
- privileged mode (already possible)
- base/bound registers (needed)
- ability to translate VA and check the bounds (needed)
- privileged instruct to update base/bound (needed)
- privileged register for exception handles 
- ability to raise exceptions, f.ex out-of-bound

**OS needed**
- memory management
	 - free list
- base bound management

**Cons**
- a lot of "internal fragmenting"


# Segmentation
*now we have 3 pairs of registers:*
- *code*
- *heap*
- *stack*

**Calculation**
- calculate offset, how far into the segment are we?
- base + offset = physical address
- offset < bounds



given a virtual address, what type is the segment
- the first two bits will specify the segment type
	- 00 is code
	- 01 is heap
	- 11 is stack
- the system knows what base address it is based on the first two bits
- the $2^2$ bits can be 4 different options
- then it will look at the offset, which is $2^{12}$ big 4096 options

- the MMU can even support protection 
- This will lead to less internal fragmentation 

| Segment | Base | Size (max 4K) | Grows Positive? | protection     |
| ------- | ---- | ------------- | --------------- | -------------- |
| Code₀₀  | 32K  | 2K            | 1               | read - execute |
| Heap₀₁  | 34K  | 3K            | 1               | read - write   |
| Stack₁₁ | 28K  | 2K            | 0               | read - write   |

*If grows negative:*
- *offset = offset - max size*
- *base + offset*

**What is needed**
- MMU has to have the segment table, and switch it in a context switch
- OS has to handle changes in wanted size of an segment
- OS has to have a free list

## Fragmenting 
*The segmenting solution ends up with segments of different sizes, something which will end up with small free bits scattered around the memory*

- This also becomes a problem when using more dynamic sizes in heap, with `malloc()` which can be shown below, where a `malloc(15)` is not possible.

| Address | 0 - 10 | 10 - 20 | 20 - 30 |
| ------- | ------ | ------- | ------- |
| Status  | Free   | Used    | Free    |

### Free List:
points from one free block to the next

- free list is implemented by a seperate linked struct
- alternative, use memory blocks to hold list pointers, each block with the next pointer of free memory
- each free block gets a header in front of it (Linux: 16 bytes)
- `*next `points to the next block in memory

```C
typedef struct __node_t {
    int size;
    struct __node_t *next;
} node_t;
```

the same way it can also be used for the memory blocks in use

```C
typedef struct header {
	int size;
	struct magic;
} header_t;
```

**magic block**
+ when we call free(), it will check the memory blocks magic number, and check if it matches your computer predefined magic number, to see if it is valid

**Splitting**

| Block Address | Length | Next Block Address |
|---------------|--------|--------------------|
| 0             | 10     | 20                 |
| 20            | 10     | NULL               |
then we do a `malloc(1)`

| Block Address | Length | Next Block Address |
|---------------|--------|--------------------|
| 0             | 10     | 20                 |
| 20            | 0      | 21                 |
| 21            | 9      | NULL               |
Simplify it:


| Block Address | Length | Next Block Address |
|---------------|--------|--------------------|
| 0             | 10     | 21                 |
| 21            | 9      | NULL               |

**Coalesce Operation**

| Block Address | Length | Next Block Address |
|---------------|--------|--------------------|
| 10            | 10     | 0                  |
| 0             | 10     | 20                 |
| 20            | 10     | NULL               |

| Block Address | Length | Next Block Address |
|---------------|--------|--------------------|
| 0             | 30     | NULL               |

**How to choose where to allocate memory?**
- Best fit:
	- Which is the closest to fit
- Worst fit:
	- Just take the most empty block
- First fit:
	- first fitting
	- small early in list
- next fit
	- we run first fit from last first fit stopped
- Buddy allocation
	- You split the allocation until it fits your `malloc(x)`
	- coalesce is easy, as if your buddy is free, you just merge

# Paging!
*Physical memory is splitted up into n many pages with an fixed size, which can hold a page each*

Virtual memory is also split into *pages*

**Page Table** 
+ The translation process is made from a table where virtual address points to a page frame 
+ the offset does not need to be affected, only the first bits representing the VPN, need to be changed to the PFN

Example:
- given 6 bit virtual address(2^6=64)
- 2 bit page number, 4 bit as offset, where each page is 16 bytes each
  
Translation:
- The offset will be the same
- vp1 -> pf7
- this will translate the first part to a physical address through the page table
- 01 -> 111 (if vp1 goes to pf7)

**Page Table structure** - 32 bit
*VPN|OFFSET*
- Is saved on RAM
- virtual page number $2^{20}$, where it uses 20 bits
- 3 bits is for reserved use
- 9 bits is for flags
	- valid/invalid
		- The valid/invalid bit in a page table entry (PTE) is used to indicate whether the page referenced by that entry is currently valid (i.e., mapped to physical memory) or invalid (i.e., not currently mapped to physical memory or not accessible).
	- read/write
	- user/superuser

# Pseudo example
```C
// Extract the VPN from the virtual address
unsigned int VPN = (VirtualAddress & VPN_MASK) >> SHIFT;

// Form the address of the page-table entry (PTE)
unsigned int PTEAddr = PTBR + (VPN * sizeof(PTE));

// Fetch the PTE
PTE = AccessMemory(PTEAddr);

// Check if process can access the page
if (PTE.Valid == 0) {
	RaiseException(SEGMENTATION_FAULT);
}
else if (CanAccess(PTE.ProtectBits) == 0) {
	RaiseException(PROTECTION_FAULT);
}
else {
	// Access OK: form physical address and fetch it
	unsigned int offset = VirtualAddress & OFFSET_MASK;
	unsigned int PhysAddr = (PTE.PFN << PFN_SHIFT) | offset;
	Register = AccessMemory(PhysAddr);
}
```

- *PTBR* is the start point of the page table
- *PTBR* + VPN(sizeof*(*PTE*) will gave the address where *PTE* is in the page-table


## TLB - Translation Lookaside Buffer
*before this, the lookup process is doubled*

This is where the TLB comes in, a part of the MMU
- It is an cache used for address translations


### Example using the TLB in the lookup process
```C
// Extract the VPN from the virtual address
VPN = (VirtualAddress & VPN_MASK) >> SHIFT;
  
// Perform a TLB lookup
(Success, TlbEntry) = TLB_Lookup(VPN);

if (Success == True) {  // TLB Hit
    if (CanAccess(TlbEntry.ProtectBits) == True) {
        Offset = VirtualAddress & OFFSET_MASK;
        PhysAddr = (TlbEntry.PFN << SHIFT) | Offset;
        Register = AccessMemory(PhysAddr);
    }
    else {
        RaiseException(PROTECTION_FAULT);
    }
}
else {  // TLB Miss
    PTEAddr = PTBR + (VPN * sizeof(PTE));
    PTE = AccessMemory(PTEAddr);
  
    if (PTE.Valid == False) {
        RaiseException(SEGMENTATION_FAULT);
    }
    else if (CanAccess(PTE.ProtectBits) == False) {
        RaiseException(PROTECTION_FAULT);
    }
    else {
        // Insert the new entry into the TLB and retry the instruction
        TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits);
        RetryInstruction();
    }
}
```


### TLB structure
*TLB can have f.ex 32, 64, or 128 elements*
- where each elements holds: VPN | PFN | flags
- TLB can eventually search through all of the elements

- If page is not in cache, it will go to access memory, and place it in TLB

**Context switch**:
- Flush
	- It could either flush/clear all the entries in the TLB
- Tagged TLB
	- each entry in the TLB is associated with an identifier for its process.
	- then when a switch happens it only changes the process identifier tag

**TLB loading** 

| Address | Values                 | Access Pattern      |
| ------- | ---------------------- | ------------------- |
| 05      |                        |                     |
| 06      | a[0]   a[1]  a[2]      | miss, hit, hit      |
| 07      | a[3]   a[4]  a[5] a[6] | miss, hit, hit, hit |
| 08      | a[7]   a[8]  a[9]      | miss, hit, hit      |
| 09      |                        |                     |
| 10      |                        |                     |

**Example on Tagged TLB**
*where Linux uses ASID for Address Space IDentifier

| VPN | PFN | valid | prot | ASID |
| --- | --- | ----- | ---- | ---- |
| 10  | 100 | 1     | rwx  | 1    |
| --  | --  | 0     | --   | --   |
| 10  | 170 | 1     | rwx  | 2    |
| --  | --  | 0     | --   | --   |

## Multi-Level page Table
The array based structures are big. 4MB for each page table.

- Large address spaces require large page tables. For example, a 4 GB address space with 4 KB pages needs over a million entries, which could take up to 4MB of memory just for the page table.
- Many of these entries may be unused (e.g., when a program uses only a small part of its address space), wasting memory.

### Page Directory
- the page table is broken down into pages
- points to different pages in memory
- now we can use same space for other memory stuff
- more steps in translation

**Example**
- virtual space: $4 KB - 2^{14}$
- Page size: $64 b = 2^6$
- Then we would have $2^8$ pages: 256
- Then we could use VPN: $2^8$ | Offset: $2^6$

- Because every entry needs $32b$ or $4B$ each the total space needed is 1 KB
	- this is assuming you are using a 32 bit system
- This will lead to 16 page tables needed

![[Pasted image 20241114153750.png]]

If we then use another page called the **Page Directory** we can then use 

So then we could use the first 4 bits to point to the correct entry in the page directory, jump to correct PFN to the 2nd table, then use the next 4 bits to find the page with the correct data, where we use the offset.
- VPN $2^8$                               | offset $2^6$
- PD index $2^4$ | PT index $2^4$ | offset $2^6$

This way if not all tables 2 tables are used, we only need 3 instead of 16

In the directory we know if a page table it pointed to do not contain any valid information, if the directory has not a checked valid flag
- in real Linux the flag is named present

If then have too many entries, you could then use multiple levels to solve this.


# Real implementation

This is why max virtual space size is 48 bits
It also uses 4 directory pages, to then save a page of 12 bits which is equivalent to 4 KB

![[Pasted image 20241114163718.png]]


# Swapping
*when RAM run empty*

**Swap space**
- virtual address $\rightarrow$ page table entry $\rightarrow$ is in physical memory
- in the Page Table a PTE can have the flag present:
	- present 1 - the file is here
	- present 0 - page miss (page fault), has to get page from swap
	- So when an address is not in use it will also have present 0
		- but the process cant use the same address again


**Process of Swapping Pages to Disk**:

- When a page is moved to swap, its contents are written to a predefined swap area on disk.
- The **Present bit** in the page table entry (PTE) for that page is cleared, indicating the page is no longer in RAM. The OS marks the disk location in the PTE or elsewhere to find the page later if needed.

**Example**
```C
PFN = FindFreePhysicalPage();
  
if (PFN == -1) {
	PFN = EvictPage();       // No free page found, use replacement algorithm
	sleep();                 // Sleep (wait for I/O)
}
  
DiskRead(PTE.DiskAddr, PFN); // Read page from disk into the physical page frame
PTE.present = true;          // Mark the page as present in the page table
PTE.PFN = PFN;               // Update the page table with the new page frame number
RetryInstruction();          // Retry the instruction that caused the page fault
```

**Page fault**
- PT entry can reuse physical address bits to block-location
- retrieve data, update PTE with physical RAM address
- Update TLB
- retry
- under `DiskRead` is the process in BLOCKED status, CPU can do other things

- The **page-fault handler** in the OS determines where the page is stored in swap, retrieves it, and loads it back into RAM.
	- page-fault handler is a little black box
	- The page-fault handler knows where to look for the swapped-out page by using the **PTE’s stored disk address** for that page.
	- And then the drivers will then get this from the
- If memory is full, the OS may use a **page replacement algorithm** to decide which page to evict to make room for the incoming page.


## Swapping policies
*which page do you swap?*

**Optimal Policy**
- replaces the page in RAM which wont be used in the longest time

**FIFO**
- replace the first one which came in

**Random**

**Least Recently used**
- implemented with a clock
- if the flag is set to 1, it is kept and is switched to 0, then it goes around through all pages, when it comes back to this it will swap it since it is 0
- Maybe set to 1 again if used?

**Dirty tag**
- A page in memory that has been changed needs to be written back when swapped.
- Unchanged page can just get the same from the copy on the disk
- PTE has a dirty flag if we change it
- some policies will throw out clean policies first

**RSS ( resident set size )**
- resident vs virtual memory
- RSS only accounts for memory that are physically present in ram
- Virtual memory includes all memory allocated to the process including parts that are currently swapped out to the disk or memory that is resserved but not yet used

