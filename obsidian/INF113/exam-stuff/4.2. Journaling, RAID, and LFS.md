
# Journaling
*used in ext3 and ext4*

Used to avoid situations where not everything gets written, so we use a journal to ensure everything gets. Basically a way to write to a continues segment, before writing it out to the storage. *Kind of a checkpoint*

After it is written to the disk, the journal entry gets cleared, and if energy goes while it writes before it clears, then it just begins writing to disk again.

`super | Journal | Group 0 | Group 1 | ... | Group N`

In the journal you write down what is going to change:
`TxB | I[v2] | B[v2] | Db | TxE`

### Consistency
- only ready when TxE is ready
- in ext4 it calculates a checksum, which will be placed in TxB 
	- TxB is checksum is self-contained as it does not depend on the following blocks 
		- The only thing that is used is the meta data about the transaction:
			- transaction ID, sequence number
			- space reserved for the checksum of the TxB block
	- Every block has a checksum which ensures that the data has not been corrupted during write
	- Unlike the TxB checksum, which only covers the TxB block, the checksum in the TxE block is calculated over **all blocks in the transaction**, including:
		- The TxB block.
		- Descriptor blocks (if present).
		- Data blocks.
		- Metadata blocks.
- This way, it can validate if the system is valid

- We are only allowed to do this because we have faster CPUs

### Consistency via transactions
*Circular log*
2 pointers is used, one to start, and one to the end, only update pointers when a checkpoint is done. This way we get a record of all the transactions needed to be done


# RAID (redundant array of independent disks)
*When FS need to be big, fast, and reliable*

The main idea behind it, is that one FS have multiple physical disks, which then can use multiple I/O at the same time, increase the memory drastically, or add redundancy. The RAID should look like one disk for the OS.

#### Level 0 - striping
- No redundance, each disk fault will lead to data loss.
- Shows what is maximal possible in capacity and performance
- Data blocks are spread evenly out, chuck size is difficult to choose
- Chunk size is how many blocks you will save in one disk before you go to the next disk

![[Pasted image 20241119162600.png]]
- *here 1 chunk is used in the left, and 2 in the right one*
- size: N disk with B blocks = $N\cdot B$
- redundance: None
- Performance:
	- Sequential: $N\cdot S$
	- Random: $N \cdot R$

### Level 1: Mirroring
- Every block is copied to another disk
- Size: $N/2 \cdot B$
- Redundance: 1 disk fault ( up to N/2 if you are lucky)
- Performance:
	- Sequential write: $N/2 \cdot S$, seq. read: $N/2 \cdot S$
		- This is mostly to ensure that the data is read in a logical sequence
	- Random read: $N\cdot R$, random write $N\cdot R/2$


### Level 4: Parity
- We use a whole disk as a "parity"
- Each stripe gets a parity block
- Here we can use XOR
- We then know if a bit has been flipped
- This way we can handle one whole disk fault
- Size: $(N-1) \cdot B$ 
- Redundance: 1 disk fault
- Performance: 
	- Sequential reads $(N-1) \cdot S$,  Sequential write: $(N - 1) \cdot S$ ( only one stripe at a time).
	- Random Read $(N-1) \cdot R$
	- Random write can be done in parallel as long as the same stripe is not being written to at the same time.
		- This is limited to the parity disk, as it can only write one parity block at a time
		- It is $R/2$, since it has to write the new parity for every stripe update.

### Level 5: Distributed Parity
- Splits the workload for the parity across the disks
- Random write $N/4 \cdot R$ 

# Log-structured FS
*If we have extra space lying around, why not use it as RAID does.*
*It will use copy-on-write*

It will gather data which will be written to memory, and do it in one long sequential write, where it will always pick a new part of the memory.
- Multiple writes gets gathered together in a write buffer

**Where is the Inodes saved?**
- LFS have a inode map (imap): inode_nr - > newest version of the inode
- The Imap is written along with the write
- The Imap denotes w

**Checkpoint Region** - CR
*Stores pointers to imaps*

- The CR is stored periodically, otherwise it is kept in memory
- Old blocks can be kept for versioning FS

**Garbage Collection Process**
- Garbage collection is necessary to reclaim space occupied by these outdated blocks.
- It will identify live blocks, which are those still referenced by the imap or directory structure
- Move all live blocks
- Mark a segment as free once all live blocks are moved to a new segment

**Crashes**
- If we use 2 CRs then FS will always be in an consistent state
- Since we never overwrite old data
	- Either an update has happened or FS looks normal

---
### Examples


**Example** of writing to LFS
1. **Checkpoint Regions (CR)**:
   - Two checkpoints (**Checkpoint 1** and **Checkpoint 2**) ensure crash recovery by pointing to the latest **imap**.

2. **Buffered Writes**:
   - Writes are accumulated in memory before being written to the log:
     - **Batch 1**: $D_1$ (data for file 1 and its corresponding inode $I$, 
     - **Batch 2**: $D_2, D_3, I$
     - **Batch 3**:  $I$ only (inode updates).

3. **Sequential Write Process**:
   - Data blocks ( $D_1, D_2, D_3$ ), inodes ( $I$ ), and the **imap** are written in sequence.

4. **Checkpoint Update**:
   - After writing, the **CR is updated** to point to the new **imap** location, ensuring consistency.

5. **Comparison to Ext**:
   - In Ext, updates overwrite existing blocks or add more blocks.
   - In LFS, updates always create a **new sequence** in the log.

6. **File Deletions**:
   - Deleted files are removed from the **imap**.
   - Unused blocks are reclaimed during garbage collection.

7. **CR Optimization**:
   - The newest **imap** is written first in the CR, enabling faster recovery.
   - the newest **imap** will be at first so that newest will always be found first in CR search, then if you want old versions

8. **Adding Files**:
   - Adding a file rewrites the folder and updates its reference to include the new file, then writes the fileâ€™s data and updates the **imap**.


Example of finding **inode k** in an LFS:
1. **Checkpoint Region (CR):**
   - The CR, stored at a fixed disk location, points to the latest **imap chunks**.
   
2. **Inode Map (Imap):**
   - The imap maps inode numbers to their current disk locations.
   - Look up **k** in the imap to get the address of **inode k**.

3. **Steps to Find Inode k:**
   - Read the CR to locate the relevant imap chunk.
   - Use the imap entry for **k** to get its disk address.
   - Read **inode k** directly from the disk.

This indirection ensures updates don't overwrite inodes and always point to the latest version. The imap is cached in memory for faster lookups.


---
# Data Integrity
*bit flips has a rate of $1E-8$ per month for a given bit*

**Latent Sector Errors** (unreadable bits, bit flips)
- Can help with error correcting code
- If a disk reports a fault in a block, then use other in a RAID
	- A latent error in another disk can lead to data loss if redundancy is insufficient.

- Some disks have limited ability to internally remap bad sectors. When a disk cannot remap, the faulty block is marked as unusable, reducing the disk's effective capacity over time.

**Block corruption**
- unreadable for disk hardware, wrong in driver-code

**Disk corruption**
- difficult to spot
- If we have found an faulty block, then replace with RAID copy
- Or a checksum can be used


## Checksum
*Will represent some information about a block> 4kB -> 8 B*

- Save checksum right before block, good if hardware support
	- can be done in one write
- collision happens, since 4kB is boiled down to 8 KB
	- So the hard  thing will be to find a divisor which spreads everything out evenly
- This can be used when you read both checksum and block from disk, then you could do a comparison

**Something which can be improved**
- use disk-id / sector number as a part of the checksum

![[Pasted image 20241120102409.png]]

**XOR**
- splits the data into 8 B of groups using some reproducible structure will then write if there is an odd number or even number of 1s in that group in its matching bit in the 8 B 
- Can't find 2 bit flips

**Sum**
- Checks the sum, this can find multiple bit flips

**CRC** - Cyclic Redundancy
- You will divide you bit string with a pre chosen value
	- In the example, it was used 1011 as a divisor
	- When doing this on all bits left, values in the remainder will pop up
	- When adding the remainder to the number you are going to do the devising on, you will become 0.
	- When this don't happen you know that a bit has been flipped

---
# ZFS

- Get rid of the raid controller
- Instead of different raids, we could instead use all the hardware
- ZFS file system is built on top of virtual storage pools called zpools
	- its basically virtual memory for ram just for storage 


### Data Integrity
- Everything is copy-on-write
	- never overwrite live data
	- on-disk state is always valid

- transactional
	- no need for journaling
	- since that it only moves the pointer if needed

- Everything is checksummed
	- No silent corruption

### End-to-end Checksum

- ZFS Checksum Trees
	- Checksum stored in parent block pointer
	- Fault isolation between data and checksum
	- entire pool is self validating
	- it updates up the hierarchy so that the hash in the parent is updated

### Mirroring
- It takes control of the hardware, so it can fix mirroring when it notice that it is broken

### ZFS Pools
- Create a pool of all the drives

### ZFS Snapshots
*Since it is log-based*

- View a file system as it was at a particular point in time
- A snapshot initially consume no disk space, but it starts to consume disk space as the files it references gets modified or deleted
- constant time

**ZFS Clones** when changes is done to old snapshots
