### Dynamic Programming Overview

Dynamic programming (DP) is a method for solving problems by breaking them into overlapping subproblems, solving each subproblem once, and storing its result. The two primary forms of DP are:

1. **Top-Down (Memoization):**
    - Start with the main problem and recursively solve smaller subproblems.
    - Store results of subproblems in a data structure (e.g., hash table or array) to avoid redundant computations.
    - Example: Recursive implementation of the Fibonacci sequence with memoization.
2. **Bottom-Up (Tabulation):**
    - Solve all subproblems iteratively, starting with the simplest cases.
    - Store results in a table (e.g., a matrix or list) and build solutions to larger problems based on the smaller ones.
    - Example: Iterative Fibonacci sequence computation.

### The flow of defining a DP problem

**Understand the subproblems**:
- Clearly define the parameters that determine a smaller version of the original problem.
- **Example**: Knapsack - $OPT(i,w)=$the maximum value achievable within the first $i$ items and capacity $w$

**Break the problem into cases**
- Think about how the solution to a larger problem depends on the solutions to the smaller problems
- **Base-Case - Example**: Knapsack
	- $OPT(0,w) = 0$
- **Recurrence - Example**: Knapsack
$$
OPT(i,w)=\max
\begin{cases}
	OPT(i-1,w)\\
	v_i+OPT(i-1, w-w_i), \text{if } w\geq w_i
\end{cases}
$$

**Choose Top-Down or Bottom-Up**
- Top-Down (Memoization):
	- Implement the recurrence relation recursively.
	- Store computed results in a data structure (e.g., a dictionary or array) to avoid re-computation.
	- *python's functools cache*
	
- Bottom-Up (Tabulation):
	- Construct a table iteratively, solving subproblems in increasing order of size.
	- Preferred for its efficiency and elimination of recursion overhead.

---

# Weighted Interval Scheduling
*Given n intervals, each with a start time, end time, and weight (value), find the largest weight sum of non-overlapping intervals.*

- Let $\text{OPT}(j)$ denote the maximum value achievable using intervals $1, 2, \ldots, j$

**Preprocessing**:
- Sort intervals by their end time. Define $p(j)$ as the largest index $i < j$ such that intervals $i$ and $j$ do not overlap. Basically the interval with closest finish time.

**Recurrence Relation**:
$$
OPT(0)=0, \text{ given that we have 1 indexation on segments}
$$

$$
OPT(j)=\max
\begin{cases}
	v_j+OPT(p(j))\\
	OPT(j-1)
\end{cases}
$$
- Here the two options are
	- Include interval $j$: Add its value $v_j$ and the best solution up to $p(j)$
	- Exclude interval $j$: Take the best solution up to


**Algorithm**
- Compute $\text{OPT}(j)$ for all $j$ using either recursion with memoization or tabulation.
- Retrieve the solutions by tracing which intervals were included

**Efficiency**
- $O(n \log n)$ with preprocessing to compute $p(j)$ and $O(n)$ for the DP table.



---

# Segmented Least Squares: Multi-way Choices
*Partition a sequence of points ${(x_1, y_1), \ldots, (x_n, y_n)}$ into segments. Fit a line to each segment such that the total cost (error of the fit + penalty for additional segments) is minimized.*

**Approach**:
1. Define $\text{Error}(i, j)$ as the cost of fitting a line to points $i$ through $j$.
	- just some black-box function 
2. Let $\text{OPT}(j)$ be the minimum cost to fit segments to the first $j$ points.
	- Base case:
$$
OPT(0)= 0
$$
    - Recurrence:
$$
OPT(j)= \min_{1\leq i \leq j}(Error(i,j)+C+OPT(i-1))
$$
		- Where $C$ is the penalty for creating new segments
		- So this will then reach a base case when a segment includes 1, since $OPT(0)=0$
3. Algorithm iteratively computes $\text{OPT}(j)$ for $j = 1$ to $n$, storing results in a DP table


---

# Subset Sums
*Find a subset of weights ${w_1, \ldots, w_n}$ that maximizes their sum while staying under a capacity $W$.*

**Approach**:
- Define $\text{OPT}(i, w)$ as the maximum weight that can be achieved using the first $i$ items with a weight limit of $w$.

**Recurrence**:
 - If the $i$-th item's weight $w_i$ exceeds the current weight limit $w$, the item cannot be included:
$$
OPT(i,w)=OPT(i-1,w), \text{ if } w_i>w
$$
- Otherwise, choose the better of:
	- Excluding the $i$-th item: $\text{OPT}(i-1, w)$.
	- Including the $i$-th item: $w_i + \text{OPT}(i-1, w-w_i)$.
$$
OPT(i,w)=\max
\begin{cases}
OPT(i-1,w)\\
w_i + OPT(i-1, w-w_i)
\end{cases}
$$
**Algorithm:**
-  Use a 2D table to compute $\text{OPT}(i, w)$ for $i = 1, \ldots, n$ and $w = 0, \ldots, W$.
-  Initialize:
	- $\text{OPT}(0, w) = 0$ for all $w$ (no items available).
- Fill the table iteratively using the recurrence.
	- or fill up using bottom up
**Final Solution:**
- $\text{OPT}(n, W)$ gives the maximum achievable weight under the capacity c

# Knapsack 1-0
*Built upon **Subset Sums**. Each item also has a value $v_i$. Maximize the total value subject to the weight constraint.*

- The 1-0 version only allows one per item

**Approach**
- Define $\text{OPT}(i, w)$ as the maximum value that can be achieved using the first $i$ items with a weight limit of $w$.

**Recurrence**
- Base case
	- $\text{OPT}(i,0)=0$
- If the $i$-th item's weight $w_i$ exceeds the current weight limit $w$, it cannot be included:
$$
\text{OPT}(i,w)= \text{OPT}(i-1,w)
$$
- Otherwise:
	- Excluding the $i$-th item: $\text{OPT}(i-1, w)$.
	- Including the $i$-th item: $v_i + \text{OPT}(i-1, w-w_i)$.
		- We use $v_i$ instead of $w_i$ here
$$
OPT(i,w)=\max
\begin{cases}
OPT(i-1,w)\\
v_i + OPT(i-1, w-w_i)
\end{cases}
$$

**Algorithm**:
- Use a 2D DP table to compute $\text{OPT}(i, w)$ for $i = 1, \ldots, n$ and $w = 0, \ldots, W$.
- Initialize:
    - $\text{OPT}(0, w) = 0$ for all $w$ (no items available).
- Fill the table iteratively using the recurrence.

**Final Solution**
- $\text{OPT}(n, W)$ gives the maximum achievable value under the weight constraint.

--- 

# Sequence Alignment

**Problem**
- Sequence alignment is used to compare two strings (or sequences), aligning them to minimize the cost of gaps (insertions/deletions) and mismatches (substitutions). It is commonly applied in bioinformatics to compare DNA, RNA, or protein sequences.

**Approach**

1. Define Subproblems:
    - Let $\text{OPT}(i, j)$ denote the minimum cost to align the first $i$ characters of sequence $X$ with the first $j$ characters of sequence $Y$.

2. Cost Model:
    - **Gap Penalty**: $\delta$ (for insertions or deletions).
	- **Mismatch Cost**: $\alpha(x_i, y_j)$ for aligning character $x_i$ in $X$ with $y_j$ in $Y$.
	- If $x_i = y_j$, the mismatch cost $\alpha(x_i, y_j)$ is usually $0$ (no penalty).

3. Base Cases:
    - Aligning a prefix of $X$ with an empty string requires gaps for every character in $X$: $OPT(i,0)=i\cdot \delta$
	- Aligning a prefix of $Y$ with an empty string requires gaps for every character in $Y$:  $OPT(0,j)=j\cdot \delta$

4. Recurrence Relation:
    - To align $x_i$ with $y_j$, we consider three cases:
	    1. Align $x_i$ with $y_j$ (substitution)
        2. Align $x_i$ with a gap in $Y$ (deletion in $Y$):
        3. Align $y_j$ with a gap in $X$ (insertion into $X$):
	- Combine these to find the minimum cost:
$$
\text{OPT}(i, j) = \min \begin{cases} 
\text{OPT}(i-1, j-1) + \alpha(x_i, y_j), \\
\text{OPT}(i-1, j) + \delta, \\
\text{OPT}(i, j-1) + \delta
\end{cases}
$$

5. Algorithm:
    - Use a 2D table to compute $\text{OPT}(i, j)$ for $i = 0, \ldots, m$ and $j = 0, \ldots, n$, where $m = |X|$ and $n = |Y|$.
    - Initialize the base cases for $i = 0$ and $j = 0$.
    - Compute each cell iteratively using the recurrence.

Final Solution:
- $\text{OPT}(m, n)$ gives the minimum alignment cost for the two sequences.
- Trackback through the DP table to reconstruct the aligned sequences.

**Example using $\delta =2$ and mismatch $\alpha(a,b) = 1$.  Using X = ACGT, and Y AGCT. In the end since mismatch were cheaper, the optimal thing were not to create any gaps, as there are only two mismatches
![[Pasted image 20241206123804.png]]
# Edit distance

**Problem**
- The **edit distance** (or Liechtenstein distance) between two strings $X$ and $Y$ is the minimum number of operations required to transform $X$ into $Y$.
- Operations allowed:
	1. **Insertion**: Add a character to $X$.
	2. **Deletion**: Remove a character from $X$.
	3. **Substitution**: Replace one character in $X$ with another.

**Approach**
1. **Define Subproblems:**
    - Let $\text{OPT}(i, j)$ denote the minimum cost (edit distance) to transform the first $i$ characters of $X$ into the first $j$ characters of $Y$.
2. **Base Cases:**
    - $\text{OPT}(i, 0) = i$: Transforming the first $i$ characters of $X$ into an empty string requires $i$ deletions.
    - $\text{OPT}(0, j) = j$: Transforming an empty string into the first $j$ characters of $Y$ requires $j$ insertions.
3. **Recurrence Relation:**
    - If $X[i] = Y[j]$, no substitution is needed: $\text{OPT}(i, j) = \text{OPT}(i-1, j-1)$
    - Otherwise, consider the three operations: 
$$
\text{OPT}(i, j) = \min
\begin{cases}
	\text{OPT}(i-1, j) + 1, \quad \text{(deletion)}\\ 
	\text{OPT}(i, j-1) + 1, \quad \text{(insertion)}\\
	\text{OPT}(i-1, j-1) + 1 \quad \text{(substitution)} 
\end{cases}
$$
4. **Algorithm:**
    - Use a 2D table to compute $\text{OPT}(i, j)$ for $i = 0, \ldots, m$ and $j = 0, \ldots, n$, where $m = |X|$ and $n = |Y|$.
    - Fill the table iteratively:
        - Start with the base cases for $i = 0$ and $j = 0$.
        - Compute $\text{OPT}(i, j)$ for increasing $i$ and $j$ using the recurrence.
5. **Final Solution:**
    - $\text{OPT}(m, n)$ gives the minimum edit distance to transform $X$ into $Y$.


**Time and Space Complexity**
- **Time Complexity:** $O(mn)$, where $m = |X|$ and $n = |Y|$, as every subproblem is computed once.
- **Space Complexity:**
    - **Standard:** $O(mn)$ for the 2D DP table.
    - **Optimized:** $O(\min(m, n))$ using a rolling array technique, as only the current and previous rows are needed.

**Example** using "Kitten" as X, and "Sitting" as Y
![[Pasted image 20241206113113.png]]

---

# Shortest Path (Bell-Ford Algorithm)

#### **Problem**
**Input**
- Directed graph $G=(V,E)$, edge weights $w:E\rightarrow \mathbb{Z}$, source $s\in V$.
- Given $\mathbb{Z}$, it can include negative weights, but no negative cycles
**Output**
- Shortest path distances $\text{dist}_G(s,v)$ for all $v\in V$, or detect a negative cycle if one exists

#### *Why Dijkstra's algorithm fails*
- **Key issue**: Once a vertex is “popped” from the priority queue in Dijkstra, its distance is finalized. Negative edge weights could mean there’s a shorter path to that vertex later, invalidating Dijkstra’s approach.
- **Attempted fix**: Shifting all edge weights to non-negative values. However:
    - This approach works for MST (Minimum Spanning Tree) but not for shortest paths.
    - It artificially inflates the cost of longer paths, leading to incorrect results.


**Key Lemma**: If G has no negative cycles, then there exists a shortest s-v path that is **simple** (contains no repeated vertices) and has at most $|V|-1$ edges.

**Proof Sketch**:
- If a path P contains a cycle C, we can remove the cycle C without increasing the cost of the path. This process simplifies the path (reduces the number of edges) while preserving its total weight, ensuring that the shortest path does not contain any unnecessary cycles.
	- Meaning that it has at most $|V|-1$ edges

#### Algorithm
*Define $DP(i,v)$ as the cost of the shortest s-v path using at most i edges.*

**Base case**:
$$
\text{DP}(0, v) =
\begin{cases} 
	0, & \text{if } v = s, \\
	\infty, & \text{otherwise.}
\end{cases}
$$

**Recursive Step** $i=1 \rightarrow |V|-1$
$$
\text{DP}(i, v) = \min 
\begin{cases}
\text{DP}(i-1, v)\\ \min_{u \in \text{pred}(v)} \big(\text{DP}(i-1, u) + w(u, v)\big)
\end{cases}
$$
- Update $\text{DP}(i,v)$ by considering
	- Not using the i-th edge ($DP(i−1,v)$).
	- Extending the path from a predecessor u of v ($DP(i−1,u)+w(u,v)$).


#### Pseudo Code
```python
from collections import defaultdict

# Initialize DP table
DP = defaultdict(lambda: float('inf'))
DP[0, s] = 0

# Bellman-Ford iterations
for i in range(1, len(V)):
    for v in V:
        DP[i, v] = DP[i-1, v]
        for u in predecessors(v):  # for all incoming neighbors of v
            cost = DP[i-1, u] + weight(u, v)
            if cost < DP[i, v]:
                DP[i, v] = cost
```


#### Detecting Negative Cycles:
- After $∣V∣−1$ iterations, perform one additional iteration.
- If any $DP(n,v) \neq DP(n-1,v)$, a negative cycle exists, as the distances continue to decrease.
- Using the Predecessor list, you can reconstruct the negative cycle.
	- Just a list of the optimal previous vertex, given a vertex, so just search through this

Time Complexity: $O(V\cdot E)$.
Space Complexity: $O(V\cdot ∣V∣)$ for the DP table (can be optimized to $O(V)$).


---

# Independent Set

#### **Problem**
**Input**
+ A tree $T = (V,E)$ with weights(v) on vertices 
**Output**
- A maximum-weight independent set $S\subseteq V$, where no two vertices in S are adjacent

**Formulation**
- Let $T_v$ denote the subtree rooted at vertex $v$ 
- Define $\text{DP}[T_v].in$ as the maximum weight of an independent set including v
- Define $\text{DP}[T_v].out$ as the maximum weight of an independent set excluding v

#### **Approach**
**Base Cases**
For leaf $\gamma$
- $\text{DP}[T_\gamma].in = \text{weight}[\gamma]$ 
- $\text{DP}[T_\gamma].out = 0$

**Recursive Step**
For an internal node v with children $\{u_1,u_2,…,u_k\}$:
1. Include v:
$$
\text{DP}[T_v].in= \text{weight}(v) + \sum_{u\in \text{children}(u)}\text{DP}[T_u].out
$$
1. Exclude v:
$$
\text{DP}[T_v].out= \sum_{u\in \text{children}(u)}\max
\begin{cases}
	\text{DP}[T_u].out\\
	\text{DP}[T_u].in
\end{cases}
$$

#### Algorithm
1. Perform a post-order traversal to compute $DP[T_v​].in$ and $DP[T_v​].out$ for each node v.
2. The final solution for the root r is: $OPT=max⁡(DP[T_r].in,DP[T_r].out)$
3. And the tree could be backtracked through prev, where it points to every neighbor if they are on or off ( two lists techically)

#### Code
```python
def postorder(v, children, weights):
    for u in children[v]:  # Process children first
        postorder(u, children, weights)
    
    DP[v]['in'] = weights[v] + sum(DP[u]['out'] for u in children[v])
    DP[v]['out'] = sum(max(DP[u]['in'], DP[u]['out']) for u in children[v])

```


