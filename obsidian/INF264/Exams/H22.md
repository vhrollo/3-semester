

type
regression

preperformaance
missing data, could be imputed, where you take the mean of other data points which are similar, this will lead to an bias.
normalization
data splitting for ubiased training

performance
MSE
MAE

``` python
# Pseudocode for model selection and evaluation
1. Load data
2. Split data into training, and test sets
3. Preprocess the training data, and then apply transforms on val and test if nessecary.
4. For each model in candidate_models:
    a. Perform cross-validation on the training set:
        - Train the model
        - Compute MAE on validation folds
5. Select the model with the best cross-validation performance

6. Do a full new training with the whole training set for the best model
7. Evaluate model on test data using MSE or MAE depending on the numbers of outliers one want to avoid
8. Then represent the results in a way that increases interpretability for your customers
	a. this could be a confusin matrix or something other visually
```

for the model candidates, a good example is start with more simple models, and try some more complex models, to find a good middle point where the model can capture the pattern without underfitting or overfitting


### Ethical concerns
-  The gender distribution could lead to a small problem, not that big
-  The pain of different cancers could differ in scale


# 6
The data itself can contain human biases and prejudice
All models have bias towards the data it was trained on

Given the continuous labels, i think it would be more natural to use performance measures more fitting for regression

Only using the first 1000 chars would mean that this would penalize people for writing too long texts

We cant judge the overfitting from looking val and test


# 7
she mixes k-means and knn, and while adressing regression she still seems to be wrong, but she at least address the prediction right if she had found the k nearst points

KNN doesnt overfit easily if you choose a high enough k