# Convolutional neural networks
*Commonly used along side image data*

**Input**
RGB image input: $width \cdot hight \cdot 3$

### Convolutional layers (sliding)
$5 \cdot 5 \cdot 3$, and 1 stride while sliding, it will then convolve over all spacial locations

An example can be:
$$32 \cdot 32 \cdot 3 \rightarrow_{5x5x3\text{ 6 layers}} 28 \cdot 28 \cdot 6 \rightarrow_{5x5x6\text{ 10 layers}} 24\cdot24\cdot10$$
- A ReLU happens at each convolution
- Padding can then be used here if the stride doesn't fit the image
- f.ex a stride of 3 with an $3x3$ filter, will not fit in a $7x7$, but if you pad it to $10x10$.

**Properties of convolution layers**
*while direct connections are sparse, units can be indirectly connected*

- In a convolutional layer, the same filter (or kernel) is applied across different regions of the input.
- For example, the connections from $x_1, x_2, x_3$ to $s_1, s_2​,$ and $s_3$​ use the **same set of weights**.
- As the filter slides across the input, it detects the same type of feature (e.g., edges, textures) in different parts of the input
![[Pasted image 20241118154511.png]]
### Pooling
![[Pasted image 20240926144726.png]]
Getting rid of redundant information. In the example we are picking the maximum activation in larger portions of the image

- Invariant to small local translations
- Down sampling

**Deep learning for natural language processing**
- Word embedding
- Word2Vec
- Breaking down words to sub-categories

**Recurrent neural networks**
- Traditional assumption: All inputs are independent
- Store a state of previous input and combine it with current input

**Autoregressive models**
- P(machine learning is fun) = P(machine) $\cdot$ P(learning|machine)....

#### How does bigger LLMs work
**Attention**
- Mechanism that allows the network to focus on specific parts of information while ignoring others

**Transformers**
- A neural network architecture that uses the attention mechanism
- Encoder

**Encoder**
- Reads the input 
- Processes the input, creates a representation("understanding") 

**Decoder**
- Reads the representation
- Produces the output


# GANs
**Generative adversarial networks ( GANs )**
- Train two neural networks that compete with each other
	- **Generator** tries to produce data that cannot be distinguished from real data
	- **Discriminator** tries to predict whether data is real or comes from the generator

**Diffusion**
- You train a model to recreate an image form noise

**Optimization**
- Optimization surface can be very complex with lots of local minima, saddle points and plateaus
- There exists several types of "tweaks"  to the SGD
	- Momentum
		- parameter update depends on the current gradient and the sum of previous gradient
	- Adaptive learning rates
		- adjust learning rate during training
		- AdaGrad, RMSProp, Adam

**Regularization**
- Deep neural networkds are extremly powerful representation
	- complex, can overfit
- parameter norm reguralization
	- add peneltaty term
- data set augmentation
	- rotate, light, zoom on a image f.ex
	- To avoid over fitting
	- create transformed or noisy data from training data

**Regularization in deep learning (cont.)**
- Early stopping
	- return the param values that resulted in lowest val err

- Dropout
	- For each minibatch, randomly ignore part of the input and hidden units
	- approx with bagged ensemble


